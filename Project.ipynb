{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Project.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bLGla3RA4Y3U"},"source":["# Sentiment Analysis with Deep Learning using BERT"]},{"cell_type":"markdown","metadata":{"collapsed":"true","id":"cK3M3O9s4Y3W"},"source":["### Prerequisites"]},{"cell_type":"markdown","metadata":{"id":"xEzXfiN64Y3W"},"source":["- Intermediate-level knowledge of Python 3 (NumPy and Pandas preferably, but not required)\n","- Exposure to PyTorch usage\n","- Basic understanding of Deep Learning and Language Models (BERT specifically)"]},{"cell_type":"markdown","metadata":{"collapsed":"true","id":"IHrfMeiD4Y3X"},"source":["### Project Outline"]},{"cell_type":"markdown","metadata":{"id":"qaGC6nzw4Y3Y"},"source":["**Task 1**: Introduction (this section)\n","\n","**Task 2**: Exploratory Data Analysis and Preprocessing\n","\n","**Task 3**: Training/Validation Split\n","\n","**Task 4**: Loading Tokenizer and Encoding our Data\n","\n","**Task 5**: Setting up BERT Pretrained Model\n","\n","**Task 6**: Creating Data Loaders\n","\n","**Task 7**: Setting Up Optimizer and Scheduler\n","\n","**Task 8**: Defining our Performance Metrics\n","\n","**Task 9**: Creating our Training Loop\n","\n","**Task 10**: Loading and Evaluating our Model"]},{"cell_type":"markdown","metadata":{"collapsed":"true","id":"zkl7bmar4Y3Y"},"source":["## Task 1: Introduction"]},{"cell_type":"markdown","metadata":{"id":"FHvErTCl4Y3Z"},"source":["### What is BERT\n","\n","BERT is a large-scale transformer-based Language Model that can be finetuned for a variety of tasks.\n","\n","For more information, the original paper can be found [here](https://arxiv.org/abs/1810.04805). \n","\n","[HuggingFace documentation](https://huggingface.co/transformers/model_doc/bert.html)\n","\n","[Bert documentation](https://characters.fandom.com/wiki/Bert_(Sesame_Street) ;)"]},{"cell_type":"markdown","metadata":{"id":"kM8hJl8e4Y3a"},"source":["<img src=\"Images/BERT_diagrams.pdf\" width=\"1000\">"]},{"cell_type":"markdown","metadata":{"id":"8hDoFRIL4Y3a"},"source":["## Task 2: Exploratory Data Analysis and Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"25ZuU0V24Y3b"},"source":["We will use the SMILE Twitter dataset.\n","\n","_Wang, Bo; Tsakalidis, Adam; Liakata, Maria; Zubiaga, Arkaitz; Procter, Rob; Jensen, Eric (2016): SMILE Twitter Emotion dataset. figshare. Dataset. https://doi.org/10.6084/m9.figshare.3187909.v2_"]},{"cell_type":"code","metadata":{"id":"xTNdsS4q4Y3b"},"source":["import torch\n","import pandas as pd\n","from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OJmtHZw4Y3f"},"source":["df = pd.read_csv('Data/smile-annotations-final.csv', \n","                 names = ['id', 'text', 'category'])\n","df.set_index('id', inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vU9Eqzt14Y3j","outputId":"4b4d6061-5b5b-4a7b-99a2-c11c9f482964"},"source":["df.text.iloc[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"zGAMPGOC4Y3q","outputId":"fbe4cc6b-1fda-4491-c6c5-ffdfc3c49a3c"},"source":["df.category.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["nocode               1572\n","happy                1137\n","not-relevant          214\n","angry                  57\n","surprise               35\n","sad                    32\n","happy|surprise         11\n","happy|sad               9\n","disgust|angry           7\n","disgust                 6\n","sad|angry               2\n","sad|disgust             2\n","sad|disgust|angry       1\n","Name: category, dtype: int64"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"8EkDKEGv4Y3u"},"source":["df = df[~df.category.str.contains('\\|')]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdnUkmJL4Y31"},"source":["df = df[df.category != 'nocode']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmFSjj5i4Y38","outputId":"88482c1d-8fbd-4e6c-ac5f-cbd5f1682d3c"},"source":["df.category.value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["happy           1137\n","not-relevant     214\n","angry             57\n","surprise          35\n","sad               32\n","disgust            6\n","Name: category, dtype: int64"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"1oubZEUw4Y4B"},"source":["possible_labels = df.category.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hYbXcxUg4Y4E"},"source":["label_dict = {}\n","for index, possible_label in enumerate(possible_labels):\n","    label_dict[possible_label] = index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJu9sIBG4Y4H","outputId":"a9a4829d-e76e-4a77-d5e8-4e4fd954fa99"},"source":["label_dict"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'happy': 0,\n"," 'not-relevant': 1,\n"," 'angry': 2,\n"," 'disgust': 3,\n"," 'sad': 4,\n"," 'surprise': 5}"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"ciN80Lse4Y4L","outputId":"b50df652-a952-45ea-8e59-11b744ee9ca2"},"source":["df['label'] = df.category.replace(label_dict)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>category</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>614484565059596288</th>\n","      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n","      <td>happy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614746522043973632</th>\n","      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n","      <td>happy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>614877582664835073</th>\n","      <td>@Sofabsports thank you for following me back. ...</td>\n","      <td>happy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>611932373039644672</th>\n","      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n","      <td>happy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>611570404268883969</th>\n","      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n","      <td>happy</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                 text  \\\n","id                                                                      \n","614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n","614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n","614877582664835073  @Sofabsports thank you for following me back. ...   \n","611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n","611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n","\n","                   category  label  \n","id                                  \n","614484565059596288    happy      0  \n","614746522043973632    happy      0  \n","614877582664835073    happy      0  \n","611932373039644672    happy      0  \n","611570404268883969    happy      0  "]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"sYGDWyuf4Y4S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJutOKDl4Y4W"},"source":["## Task 3: Training/Validation Split"]},{"cell_type":"code","metadata":{"id":"O-4FC0n84Y4X"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSzdpQSz4Y4a"},"source":["x_train, x_val, y_train, y_val =train_test_split(\n","df.index.values,\n","df.label.values,\n","test_size=0.15,\n","random_state=17,\n","stratify=df.label.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkLqU0QS4Y4c"},"source":["df['data_type'] = ['not_set']*df.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXWBL1Zk4Y4f"},"source":["df.loc[x_train, 'data_type'] = 'train'\n","df.loc[x_val, 'data_type'] = 'val'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6FiGUXG54Y4j","outputId":"a3ac33b3-2de0-4086-f598-433a9a99ac88"},"source":["df.groupby(['category', 'label', 'data_type']).count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>category</th>\n","      <th>label</th>\n","      <th>data_type</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">angry</th>\n","      <th rowspan=\"2\" valign=\"top\">2</th>\n","      <th>train</th>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">disgust</th>\n","      <th rowspan=\"2\" valign=\"top\">3</th>\n","      <th>train</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">happy</th>\n","      <th rowspan=\"2\" valign=\"top\">0</th>\n","      <th>train</th>\n","      <td>966</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>171</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n","      <th rowspan=\"2\" valign=\"top\">1</th>\n","      <th>train</th>\n","      <td>182</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">sad</th>\n","      <th rowspan=\"2\" valign=\"top\">4</th>\n","      <th>train</th>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">surprise</th>\n","      <th rowspan=\"2\" valign=\"top\">5</th>\n","      <th>train</th>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>val</th>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              text\n","category     label data_type      \n","angry        2     train        48\n","                   val           9\n","disgust      3     train         5\n","                   val           1\n","happy        0     train       966\n","                   val         171\n","not-relevant 1     train       182\n","                   val          32\n","sad          4     train        27\n","                   val           5\n","surprise     5     train        30\n","                   val           5"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"jpdQDuiq4Y4o"},"source":["## Task 4: Loading Tokenizer and Encoding our Data"]},{"cell_type":"code","metadata":{"id":"WyctXfZR4Y4o"},"source":["from transformers import BertTokenizer\n","from torch.utils.data import TensorDataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpRnV0fW4Y4t"},"source":["tokenizer = BertTokenizer.from_pretrained(\n","'bert-base-uncased',\n","do_lower_case=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVCQcAKN4Y4v"},"source":["encoded_data_train = tokenizer.batch_encode_plus(\n","df[df.data_type=='train'].text.values,\n","add_special_tokens=True,\n","return_attention_mask=True,\n","pad_to_max_length=True,\n","max_length=256,\n","return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xH-mNJsi4Y4y"},"source":["encoded_data_val = tokenizer.batch_encode_plus(\n","df[df.data_type=='val'].text.values,\n","add_special_tokens=True,\n","return_attention_mask=True,\n","pad_to_max_length=True,\n","max_length=256,\n","return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6tQXsq24Y44"},"source":["input_ids_train = encoded_data_train['input_ids']\n","attention_masks_train = encoded_data_train['attention_mask']\n","labels_train = torch.tensor(df[df.data_type=='train'].label.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CcCYIc6P4Y47"},"source":["input_ids_val = encoded_data_val['input_ids']\n","attention_masks_val = encoded_data_val['attention_mask']\n","labels_val = torch.tensor(df[df.data_type=='val'].label.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47Fh42zv4Y4_"},"source":["dataset_train = TensorDataset(input_ids_train, attention_masks_train,\n","                              labels_train)\n","dataset_val = TensorDataset(input_ids_val, attention_masks_val, \n","                           labels_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaKQClYc4Y5C","outputId":"e757dbdd-b597-47d1-8acb-e04bc32a4f93"},"source":["len(dataset_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1258"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"BCTWMLY74Y5F"},"source":["## Task 5: Setting up BERT Pretrained Model"]},{"cell_type":"code","metadata":{"id":"MyDvduxn4Y5G"},"source":["from transformers import BertForSequenceClassification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kd_fXdi84Y5I"},"source":["model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n","                                      num_labels=len(label_dict),\n","                                     output_attentions=False,\n","                                     output_hidden_states=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uMinehtk4Y5L"},"source":["## Task 6: Creating Data Loaders"]},{"cell_type":"code","metadata":{"id":"xHhQ4GWB4Y5L"},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z09VL3454Y5P"},"source":["batch_size = 4\n","\n","data_loader_train = DataLoader(\n","    dataset_train, sampler=RandomSampler(dataset_train),\n","    batch_size=batch_size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vJNsQmr4Y5S"},"source":["data_loader_val = DataLoader(\n","    dataset_val, sampler=RandomSampler(dataset_val),\n","    batch_size=32\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wmj0-55S4Y5V"},"source":["## Task 7: Setting Up Optimizer and Scheduler"]},{"cell_type":"code","metadata":{"id":"cRm2dN504Y5W"},"source":["from transformers import AdamW, get_linear_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqjK1Tbl4Y5b"},"source":["optimizer = AdamW(\n","model.parameters(),\n","lr=1e-5, #2e-5>5e-5\n","eps=1e-8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hQ41Bk14Y5d"},"source":["epochs=10\n","scheduler = get_linear_schedule_with_warmup(\n","optimizer,\n","num_warmup_steps=0,\n","num_training_steps=len(data_loader_train)*epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2TpkCdwZ4Y5h"},"source":["## Task 8: Defining our Performance Metrics"]},{"cell_type":"markdown","metadata":{"id":"wCCecUfX4Y5h"},"source":["Accuracy metric approach originally used in accuracy function in [this tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification)."]},{"cell_type":"code","metadata":{"id":"xJcKmrhT4Y5i"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"poUH8mJt4Y5n"},"source":["from sklearn.metrics import f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"02POYYXI4Y5s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BhlZwUj4Y5v"},"source":["def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iquh2zMu4Y5x"},"source":["def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels+flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n","    return f1_score(labels_flat, preds_flat, average='weighted')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z1OTEgFn4Y51"},"source":["## Task 9: Creating our Training Loop"]},{"cell_type":"markdown","metadata":{"id":"C1GVUhk94Y52"},"source":["Approach adapted from an older version of HuggingFace's `run_glue.py` script. Accessible [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128)."]},{"cell_type":"code","metadata":{"id":"7ZzIbCs54Y53"},"source":["import random\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SsCD1L-k4Y56","outputId":"d938244b-f22f-4810-b821-36685f917b65"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wKFRAEnw4Y5-"},"source":["def evaluate(dataloader_val):\n","\n","    model.eval()\n","    \n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","    \n","    for batch in dataloader_val:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)\n","            \n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","    \n","    loss_val_avg = loss_val_total/len(dataloader_val) \n","    \n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","            \n","    return loss_val_avg, predictions, true_vals\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVaiYyjy4Y6B","outputId":"820ab8ed-e1ce-4359-e2dd-cd81480410c4"},"source":["for epoch in tqdm(range(1, epochs+1)):\n","    model.train()\n","    loss_train_total = 0\n","    \n","    progress_bar = tqdm(data_loader_train,\n","                       desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","    for batch in progress_bar:\n","        model.zero_grad()\n","        batch = tuple(b.to(device) for b in batch)\n","        inputs = {\n","            'input_ids' : batch[0],\n","            'attention_mask': batch[1],\n","            'labels': batch[2]\n","            \n","        }\n","        outputs = model(**inputs)\n","        loss = outputs[0]\n","        loss_train_total+=loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        progress_bar.set_postfix({'training_loss': '{:3f}'.format(loss.item()/len(batch))})\n","        \n","    torch.save(model.state_dict(), f'Models/BERT_ft_epoch{epoch}.model')\n","    tqdm.write('\\nEpoch {epoch}')\n","    loss_train_avg = loss_train_total/len(dataloader)\n","    tqdm.write(f'Training loss: {loss_train_avg}')\n","    val_loss, predictions, true_vals = evaluate(data_loader_val)\n","    val_f1 = f1_score_func(predictions, true_vals)\n","    tqdm.write(f'Validation loss: {val_loss}')\n","    tqdm.write(f'F1 Score: (weighted): {val_f1}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7be265b3035d4041bd3e0695f523afd0","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a1cc9f3ba754a2a93f46f01cbc8cc98","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=315.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"lTdl0kb24Y6E"},"source":["## Task 10: Loading and Evaluating our Model"]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"bqYlJ39A4Y6F"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=len(label_dict),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"64ppAeAu4Y6I"},"source":["model.to(device)\n","pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"vem_GNvu4Y6L"},"source":["model.load_state_dict(\n","torch.load('Models/finetuned_bert_epoch_1_gpu_trained.model',\n","          map_location=torch.device('cpu')))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"mdeKRSlQ4Y6N"},"source":["_, predictions, true_vals = evaluate(data_loader_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"is43DAax4Y6Q"},"source":["accuracy_per_class(predictions, true_vals)"],"execution_count":null,"outputs":[]}]}